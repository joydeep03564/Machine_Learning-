{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic-Image Seg_Polyp_Det.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNG0YBvK4A9HVYF+HCtmuJ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joydeep03564/Machine_Learning-/blob/master/Semantic_Image_Seg_Polyp_Det.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKaEmZS9xPMz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhzMjvD8v-G-",
        "outputId": "d296e88e-52ff-4514-fcc4-c2bf0e69b394"
      },
      "source": [
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGjC5cPGxNqq"
      },
      "source": [
        "# Importing the necessary libraries \r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import cv2\r\n",
        "import os  # This library is used to join the paths of the image folder\r\n",
        "from glob import glob\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import *\r\n",
        "from tensorflow.keras.models import Model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIJ4sXWPzt5v"
      },
      "source": [
        "# Load dataset # Data sanity check: splited the data set into training,validation and test\r\n",
        "def load_data(path, split=0.1):\r\n",
        "    images = sorted(glob(os.path.join(path, \"images/*\")))\r\n",
        "    masks = sorted(glob(os.path.join(path, \"masks/*\")))\r\n",
        "\r\n",
        "    total_size=len(images)\r\n",
        "    valid_size=int(split*total_size)\r\n",
        "    test_size=int(split*total_size)\r\n",
        "    # Spliting the whole dataset into training and validation according to the split values\r\n",
        "    train_x,valid_x=train_test_split(images,test_size=valid_size,random_state=42)\r\n",
        "    train_y,valid_y=train_test_split(masks,test_size=valid_size,random_state=42)\r\n",
        "    # Spliting again the training set into test using the 'test size' split \r\n",
        "    train_x,test_x=train_test_split(train_x,test_size=test_size,random_state=4)\r\n",
        "    train_y,test_y=train_test_split(train_y,test_size=test_size,random_state=4)\r\n",
        "    \r\n",
        "    \r\n",
        "\r\n",
        "    return (train_x,train_y), (valid_x,valid_y),(test_x,test_y)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_Qwx7UcL3Cb"
      },
      "source": [
        "def read_image(path):\r\n",
        "    path=path.decode()\r\n",
        "    x = cv2.imread(path,cv2.IMREAD_COLOR)\r\n",
        "    x = cv2.resize(x,(256,256))\r\n",
        "    x=  x/255.0\r\n",
        "    #x=  x.astype(np.float32) #check this line\r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENLCagA8aG29"
      },
      "source": [
        "def read_mask(path):\r\n",
        "    path=path.decode()\r\n",
        "    x=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\r\n",
        "    x = cv2.resize(x,(256,256))\r\n",
        "    x=np.expand_dims(x,axis=-1)\r\n",
        "    x=  x/255.0\r\n",
        "    #x=  x.astype(np.float32) # check this line\r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoYpmN0UeQb5"
      },
      "source": [
        "# tf_parse is nothing but reading the images and and then converting it to the tensorflow type.\r\n",
        "# It is kind of pre-processed image which is going to used by tf.data.Dataset while creating the datasource for the pipeline\r\n",
        "def tf_parse(x, y):\r\n",
        "    def _parse(x, y):\r\n",
        "        x = read_image(x)\r\n",
        "        y = read_mask(y)\r\n",
        "        return x, y\r\n",
        "\r\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\r\n",
        "    x.set_shape([256, 256, 3])\r\n",
        "    y.set_shape([256, 256, 1])\r\n",
        "    return x, y\r\n",
        "#This tf_dataset function is the main function. \r\n",
        "#To create an input pipeline, you must start with a data source. \r\n",
        "#For example, to construct a Dataset from data in memory, you can use tf.data.Dataset.from_tensors() or tf.data.Dataset.from_tensor_slices()\r\n",
        "def tf_dataset(x, y, batch=8):\r\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\r\n",
        "    dataset = dataset.map(tf_parse)\r\n",
        "    dataset = dataset.batch(batch)\r\n",
        "    dataset = dataset.repeat()\r\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8WS7x0yI5dT"
      },
      "source": [
        "# from keras.models import *\r\n",
        "# from keras.layers import *\r\n",
        "# from keras.optimizers import *\r\n",
        "# from keras.callbacks import ModelCheckpoint, LearningRateScheduler\r\n",
        "# from keras import backend as keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHSIkqubDsCu"
      },
      "source": [
        "def build_model():\r\n",
        "  size=256\r\n",
        "  inputs=Input((size,size,3))\r\n",
        "  conv1= Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(inputs)   # First Conv layer followed by Maxpool\r\n",
        "  conv1= Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(conv1)\r\n",
        "  pool1= MaxPooling2D(pool_size=(2,2))(conv1)\r\n",
        "\r\n",
        "  conv2=Conv2D(filters=128,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(pool1)   # Second conv layer followed by Maxpool\r\n",
        "  conv2=Conv2D(filters=128,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(conv2)\r\n",
        "  pool2= MaxPooling2D(pool_size=(2,2))(conv2)\r\n",
        "\r\n",
        "  conv3=Conv2D(filters=256,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(pool2)  # Third con layer followed by MAXpool\r\n",
        "  conv3=Conv2D(filters=256,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(conv3)\r\n",
        "  pool3=MaxPooling2D(pool_size=(2,2))(conv3)\r\n",
        "\r\n",
        "  conv4=Conv2D(filters=512,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(pool3)  # 4th conv layer followed by Macpool and added Drop out for avoiding overfitting \r\n",
        "  conv4=Conv2D(filters=512,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(conv4)\r\n",
        "  drop4=Dropout(0.5)(conv4)\r\n",
        "  pool4=MaxPooling2D(pool_size=(2,2))(drop4)\r\n",
        "\r\n",
        "  conv5=Conv2D(filters=1024,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(pool4) #  5th conv layer followed by Maxpool and added Drop out for avoiding overfitting \r\n",
        "  conv5=Conv2D(filters=1024,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(conv5)\r\n",
        "  drop5=Dropout(0.5)(conv5)\r\n",
        "\r\n",
        "  # We will implement the copy crop and upsampling or bridge part of the U- Net\r\n",
        "\r\n",
        "  upconv6 =(UpSampling2D(size=(2,2)))(drop5)\r\n",
        "  up6=Conv2D(filters=512,kernel_size=2,activation='relu',padding='same',kernel_initializer='he_normal')(upconv6)\r\n",
        "  merge6=concatenate([drop4,up6],axis=3)\r\n",
        "  # here first we upsampling the image and then applying convolution on top of the that.\r\n",
        "  # As the size of the image is similar we are just concatenating in the crop and copy stage\r\n",
        "  conv6=Conv2D(filters=512,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(merge6)\r\n",
        "  conv6=Conv2D(filters=512,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(conv6)\r\n",
        "\r\n",
        "\r\n",
        "  upconv7 = (UpSampling2D(size=(2,2)))(conv6)\r\n",
        "  up7=Conv2D(filters=256,kernel_size=2,activation='relu',padding='same',kernel_initializer='he_normal')(upconv7)\r\n",
        "  merge7=concatenate([conv3,up7],axis=3)\r\n",
        "  conv7=Conv2D(filters=256,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(merge7)\r\n",
        "  conv7=Conv2D(filters=256,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(conv7)\r\n",
        "\r\n",
        "  upconv8 = (UpSampling2D(size=(2,2)))(conv7)\r\n",
        "  up8=Conv2D(filters=128,kernel_size=2,activation='relu',padding='same',kernel_initializer='he_normal')(upconv8)\r\n",
        "  merge8=concatenate([conv2,up8],axis=3)\r\n",
        "  conv8=Conv2D(filters=128,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(merge8)\r\n",
        "  conv8=Conv2D(filters=128,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(conv8)\r\n",
        "\r\n",
        "  upconv9 = (UpSampling2D(size=(2,2)))(conv8)\r\n",
        "  up9=Conv2D(filters=64,kernel_size=2,activation='relu',padding='same',kernel_initializer='he_normal')(upconv9)\r\n",
        "  merge9=concatenate([conv1,up9])\r\n",
        "  conv9=Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(merge9)\r\n",
        "  conv9=Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(conv9)\r\n",
        "  conv9=Conv2D(filters=2,kernel_size=3,activation='relu',padding='same',kernel_initializer='he_normal')(conv9)\r\n",
        "  conv10=Conv2D(filters=1,kernel_size=1,activation='sigmoid')(conv9)\r\n",
        "\r\n",
        "  model=Model(inputs,conv10)\r\n",
        "\r\n",
        "  # model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "  return model\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNL-ll82qt4B"
      },
      "source": [
        "\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\r\n",
        "\r\n",
        "def iou(y_true, y_pred):\r\n",
        "     def f(y_true, y_pred):\r\n",
        "         intersection = (y_true * y_pred).sum()\r\n",
        "         union = y_true.sum() + y_pred.sum() - intersection\r\n",
        "         x = (intersection + 1e-15) / (union + 1e-15)\r\n",
        "         x = x.astype(np.float32)\r\n",
        "         return x\r\n",
        "     return tf.numpy_function(f, [y_true, y_pred], tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqA4hIPL3b9Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3709b7bf-a42d-4781-ec40-4188747265fa"
      },
      "source": [
        "if __name__ == \"__main__\":\r\n",
        "  path=\"/content/drive/MyDrive/Medical_Imaging /Bio_medical_imageSegmentation/Kvasir-Polyp-detection/Kvasir-SEG\"\r\n",
        "  (train_x,train_y), (valid_x,valid_y),(test_x,test_y)=load_data(path,split=0.1)\r\n",
        "  \r\n",
        "  # print(f\"Training datatset Length :{len(train_x)} and Training Y :{len(train_y)} \")\r\n",
        "  # print(f\"Validation dataset Length: Valid_x {len(valid_x)} and Valid_y {len(valid_y)}\")\r\n",
        "  # print(f\"Test dataset : text_x is :{len(test_x)} and Valid y {len(test_y)}\")\r\n",
        "  # x=read_image(valid_x[0])\r\n",
        "  # print(x.shape)\r\n",
        "  # y=read_mask(valid_y[0])\r\n",
        "  # print(y.shape)\r\n",
        "  \r\n",
        "# Here we are checking the sanity of the load function\r\n",
        "# Image at 750 is below 512\r\n",
        "  ds=tf_dataset(test_x,test_y)\r\n",
        "  for x,y in ds:\r\n",
        "    print(x.shape)\r\n",
        "    print(y.shape)\r\n",
        "    break\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8, 256, 256, 3)\n",
            "(8, 256, 256, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecui4xptb8p_"
      },
      "source": [
        "## Hyperparameters\r\n",
        "## Hyperparameters\r\n",
        "batch=8\r\n",
        "lr = 1e-4\r\n",
        "epochs = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slGAW9bFXlxW"
      },
      "source": [
        "train_dataset = tf_dataset(train_x, train_y, batch=batch)\r\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N4z2aLiuPeK"
      },
      "source": [
        "model = build_model()\r\n",
        "opt = tf.keras.optimizers.Adam(lr)\r\n",
        "metrics = [\"acc\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), iou]\r\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=metrics)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqp3vj_iJk_L"
      },
      "source": [
        "callbacks = [\r\n",
        "          ModelCheckpoint(\"files/model.h5\"),\r\n",
        "          ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\r\n",
        "          CSVLogger(\"files/data.csv\"),\r\n",
        "          TensorBoard(),\r\n",
        "          EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=False)\r\n",
        "     ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m299cWaxtW_W",
        "outputId": "4b2edcd1-34c5-48e3-ef78-621cd4b02fa9"
      },
      "source": [
        "train_steps = len(train_x)//batch\r\n",
        "valid_steps = len(valid_x)//batch\r\n",
        "\r\n",
        "\r\n",
        "if len(train_x) % batch != 0:\r\n",
        "        train_steps += 1\r\n",
        "if len(valid_x) % batch != 0:\r\n",
        "        valid_steps += 1\r\n",
        "\r\n",
        "model.fit(train_dataset,\r\n",
        "validation_data=valid_dataset,\r\n",
        "epochs=epochs,\r\n",
        "steps_per_epoch=train_steps,\r\n",
        "validation_steps=valid_steps,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - 513s 5s/step - loss: 0.4716 - acc: 0.8318 - recall_3: 0.0092 - precision_3: 0.1193 - iou: 0.1020 - val_loss: 0.4119 - val_acc: 0.8306 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00 - val_iou: 0.1500\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 61s 612ms/step - loss: 0.3796 - acc: 0.8415 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00 - iou: 0.1453 - val_loss: 0.3891 - val_acc: 0.8306 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00 - val_iou: 0.1713\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 61s 607ms/step - loss: 0.3617 - acc: 0.8415 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00 - iou: 0.1616 - val_loss: 0.3728 - val_acc: 0.8306 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00 - val_iou: 0.1634\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 60s 600ms/step - loss: 0.3468 - acc: 0.8415 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00 - iou: 0.1692 - val_loss: 0.4123 - val_acc: 0.8306 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00 - val_iou: 0.1789\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 60s 602ms/step - loss: 0.3409 - acc: 0.8415 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00 - iou: 0.1802 - val_loss: 0.4146 - val_acc: 0.8306 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00 - val_iou: 0.1774\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 60s 602ms/step - loss: 0.3339 - acc: 0.8415 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00 - iou: 0.1839 - val_loss: 0.3522 - val_acc: 0.8306 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00 - val_iou: 0.1711\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 60s 601ms/step - loss: 0.3186 - acc: 0.8415 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00 - iou: 0.1935 - val_loss: 0.3513 - val_acc: 0.8306 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00 - val_iou: 0.1854\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 60s 601ms/step - loss: 0.3172 - acc: 0.8415 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00 - iou: 0.1990 - val_loss: 0.3743 - val_acc: 0.8306 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00 - val_iou: 0.1703\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 60s 602ms/step - loss: 0.3158 - acc: 0.8415 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00 - iou: 0.1998 - val_loss: 0.3542 - val_acc: 0.8306 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00 - val_iou: 0.1692\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 60s 601ms/step - loss: 0.3096 - acc: 0.8415 - recall_3: 1.1798e-07 - precision_3: 0.1213 - iou: 0.2036 - val_loss: 0.3282 - val_acc: 0.8306 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00 - val_iou: 0.1974\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 60s 600ms/step - loss: 0.2925 - acc: 0.8415 - recall_3: 4.4647e-06 - precision_3: 0.6051 - iou: 0.2185 - val_loss: 0.3792 - val_acc: 0.8306 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00 - val_iou: 0.1371\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 60s 602ms/step - loss: 0.2948 - acc: 0.8415 - recall_3: 2.2698e-04 - precision_3: 0.5980 - iou: 0.2130 - val_loss: 0.3383 - val_acc: 0.8306 - val_recall_3: 5.4057e-06 - val_precision_3: 1.0000 - val_iou: 0.1716\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 60s 601ms/step - loss: 0.2840 - acc: 0.8475 - recall_3: 0.0676 - precision_3: 0.7067 - iou: 0.2275 - val_loss: 0.3013 - val_acc: 0.8611 - val_recall_3: 0.2094 - val_precision_3: 0.8874 - val_iou: 0.2310\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 60s 601ms/step - loss: 0.2578 - acc: 0.8837 - recall_3: 0.4309 - precision_3: 0.7483 - iou: 0.3042 - val_loss: 0.2985 - val_acc: 0.8639 - val_recall_3: 0.2196 - val_precision_3: 0.9198 - val_iou: 0.2507\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 60s 603ms/step - loss: 0.2533 - acc: 0.8851 - recall_3: 0.4165 - precision_3: 0.7745 - iou: 0.3188 - val_loss: 0.2880 - val_acc: 0.8660 - val_recall_3: 0.2406 - val_precision_3: 0.8977 - val_iou: 0.2480\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 60s 599ms/step - loss: 0.2364 - acc: 0.8927 - recall_3: 0.4752 - precision_3: 0.7862 - iou: 0.3466 - val_loss: 0.2729 - val_acc: 0.8744 - val_recall_3: 0.2943 - val_precision_3: 0.9059 - val_iou: 0.2845\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 60s 599ms/step - loss: 0.2278 - acc: 0.8987 - recall_3: 0.5187 - precision_3: 0.7927 - iou: 0.3754 - val_loss: 0.2591 - val_acc: 0.8844 - val_recall_3: 0.3627 - val_precision_3: 0.9101 - val_iou: 0.3279\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 60s 599ms/step - loss: 0.2108 - acc: 0.9076 - recall_3: 0.5582 - precision_3: 0.8268 - iou: 0.4151 - val_loss: 0.2616 - val_acc: 0.8858 - val_recall_3: 0.4203 - val_precision_3: 0.8364 - val_iou: 0.3396\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 60s 600ms/step - loss: 0.1983 - acc: 0.9127 - recall_3: 0.5959 - precision_3: 0.8309 - iou: 0.4410 - val_loss: 0.2709 - val_acc: 0.8832 - val_recall_3: 0.4324 - val_precision_3: 0.7987 - val_iou: 0.3385\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 60s 599ms/step - loss: 0.1873 - acc: 0.9172 - recall_3: 0.6237 - precision_3: 0.8386 - iou: 0.4633 - val_loss: 0.2499 - val_acc: 0.8935 - val_recall_3: 0.4577 - val_precision_3: 0.8665 - val_iou: 0.3630\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc1a2052eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    }
  ]
}